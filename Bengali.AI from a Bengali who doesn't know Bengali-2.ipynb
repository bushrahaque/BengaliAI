{"cells":[{"metadata":{"_uuid":"90694059-8db4-422c-95af-d1f331347437","_cell_guid":"806ecace-24b9-42b0-a91b-886ef5359090","trusted":true},"cell_type":"code","source":"# %% [markdown]\n# My submission for the Bengali.AI challenge available on Kaggle.\n# \n# My motivation for this project is to learn a little bit about the language which I grew up with but have since forgotten due to lack of practice. Hopefully some of the grapheme (i.e. a Benagali letter) components will be familiar to me.\n# \n# The goal of this Kaggle competition is to be able to identify the unique grapheme components of a given grapheme. A grapheme can have 3 components: the root, the vowel diacritic and the consonant diacritic. \n\n# %% [markdown]\n# #### Load Libraries\n\n# %% [code]\n# Load libraries \n\n# Data manipulation \nimport numpy as np\nimport pandas as pd\n\n# Data viz\nimport matplotlib.pyplot as pt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nimport PIL.Image as Image\nimport PIL.ImageDraw as ImageDraw\nimport PIL.ImageFont as ImageFont\n\nimport cv2 as cv2\n\n%matplotlib inline\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow import keras\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import * \n    # will use Input, Conv2D, MaxPool2D, BatchNormalization Dropout, Flatten, Dense\nfrom keras.callbacks import LearningRateScheduler\n\n# Ignore warnings (oops! my bad)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Miscellaneous/Ad-hoc\nfrom timeit import default_timer as timer\nimport math\nimport gc \n\nprint('Libraries successfully imported!')\n\n# %% [markdown]\n# #### Load Data\n\n# %% [code]\n# Load data from Kaggle\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nprint('Data successfully imported!')\n\n# %% [code]\n# Read data into Pandas dataframes\n\ntrain = pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\ntest = pd.read_csv('/kaggle/input/bengaliai-cv19/test.csv')\nclass_map = pd.read_csv('/kaggle/input/bengaliai-cv19/class_map.csv')\n\n# %% [markdown]\n# ## Data Exploration\n\n# %% [code]\ntrain.shape\n\n# %% [code]\ntest.shape\n\n# %% [code]\ntrain.columns\n\n# %% [code]\ntest.columns\n\n# %% [code]\ntrain.head()\n\n# %% [code]\ntest.head()\n\n# %% [markdown]\n# At a higher level, the train dataset has an an incredible number of graphemes to train a ML model, however a very smaller number to test it. The train dataset has each row corresponding to an image of a grapheme, along with which grapheme_root, vowel_diacritic and consonant_diacritic featured in the grapheme. The actual alphabet is also included. \n# \n# The test dataset is of a different structure, and instead has 3 rows corresponding to one image of a grapheme. The three rows correspond to the grapheme_root, vowel_diacritic and consonant_diacritic. \n\n# %% [code]\n# Find number of unique components \n\nnum_roots = train.grapheme_root.nunique()\nnum_v_diacritics = train.vowel_diacritic.nunique()\nnum_c_diacritics = train.consonant_diacritic.nunique()\n\nprint('There are', num_roots, 'grapheme roots in the train dataset.')\nprint('There are', num_v_diacritics, 'vowel diacritics in the train dataset.')\nprint('There are', num_c_diacritics, 'consonant diacritics in the train dataset.')\n\n# %% [markdown]\n# #### Visualization:\n\n# %% [code]\n# Plot distribution of grapheme roots \n\nsns.set_style('darkgrid')\npt.figure(figsize=(20,10))\nsns.countplot(x='grapheme_root', data=train, palette='mako_r')\npt.xticks(rotation=90)\npt.title('Distribution of Grapheme Roots')\n\n# %% [markdown]\n# In the train dataset, there is enormous variance on which grapheme roots are seen. This may lead to overfitting (underfitting) for some roots since there the model will be trained too precisely (or not precisely enough).\n\n# %% [code]\n# Plot distribution of vowel diacritics\n\nsns.set_style('darkgrid')\npt.figure(figsize=(20,10))\nsns.countplot(x='vowel_diacritic', data=train, palette='mako_r')\npt.xticks(rotation=90)\npt.title('Distribution of Vowel Diacritics')\n\n# %% [markdown]\n# Again, it is evident that the data is not uniformly distributed and there might be over/underfitting.\n\n# %% [code]\n# Plot distribution of consonant diacritics\n\nsns.set_style('darkgrid')\npt.figure(figsize=(20,10))\nsns.countplot(x='consonant_diacritic', data=train, palette='mako_r')\npt.xticks(rotation=90)\npt.title('Distribution of Consonant Diacritics')\n\n# %% [markdown]\n# This distribution plot shows an non-uniform distribution with type 0 being the most popular. \n# \n# Note that although the above plots show non-uniformity, it may be because some components (of the 3) tend to be used more frequently in the overall graphemes.\n\n# %% [code]\nclass_map.shape\n\n# %% [code]\nclass_map.columns\n\n# %% [code]\nclass_map.head()\n\n# %% [code]\n# Splitting the components into their own datasets\n\nroots = class_map.loc[class_map.component_type == 'grapheme_root']\nv_diacritics = class_map.loc[class_map.component_type == 'vowel_diacritic']\nc_diacritics = class_map.loc[class_map.component_type == 'consonant_diacritic']\n\n# %% [markdown]\n# The class_map dataset contains information for identifying each component. It identifies the component type, a unique label and a visual representation. \n# \n# The following visualizations will help to gain a better understanding of graphemes. Only the top 10% of roots are considered, however all diacritics (both vowel and consonant) will be visualized. Note that the following visualizations will utilize external font data (Kalpurush Fonts) which is available on Kaggle as well. \n\n# %% [code] {\"_kg_hide-output\":true}\n# Grapheme Roots viz \n\n# Get top 10% of roots\ntop10 = int(0.10 * len(roots))\nroots['count'] = 0 \n\n# Format data \nfor label in roots.label.unique():\n    label_count = len(train.loc[train.grapheme_root == label])\n    roots.loc[label, 'count'] = label_count\n\nroots_sorted = roots.sort_values('count', ascending=False)\n\n# %% [code]\n# Vowel Diacritics viz\n\neleven = 11\nv_diacritics['count'] = 0\nv_ind_start = 168\n\n# Format data \nfor label in v_diacritics.label.unique():\n    label_count = len(train.loc[train.vowel_diacritic == label])\n    v_diacritics.at[(v_ind_start + label), 'count'] = label_count\n\n# %% [code]\n# Consonant Diacritics viz\n\nseven = 7\nc_diacritics['count'] = 0\nc_ind_start = 179\n\n# Format data \nfor label in c_diacritics.label.unique():\n    label_count = len(train.loc[train.consonant_diacritic == label])\n    c_diacritics.at[(c_ind_start + label), 'count'] = label_count\n\n# %% [markdown]\n# Then the top 10 most popular grapheme roots, and the diacritics are:\n\n# %% [code]\nroots_sorted.head(top10)\n\n# %% [code]\nv_diacritics.head(eleven)\n\n# %% [code]\nc_diacritics.head(seven)\n\n# %% [code]\n# Clear memory\n\ndel test, class_map\ndel roots, v_diacritics, c_diacritics\ngc.collect()\n\n# %% [markdown]\n# ## Building the Model\n\n# %% [markdown]\n# The CNN will be built using the Model function API available in the Keras package. The Sequential model CANNOT be used because it does not allow multi-outputs which is required for this problem.\n\n# %% [code]\n# Important variables \n\n# Compiling the model\noptimizer = 'adam' # typically outperforms other adaptive momentum techniques\nloss_func = 'categorical_crossentropy' # useful for finding probabilities for classification problems with > 2 classes\nmetric = ['accuracy'] # 'categorial_accuracy' will be detected automatically by Keras\n\n# Adding layers\nimg_size = 64\nnum_channels = 1\nReLU = 'relu'\nSoftmax = 'softmax'\npadding = 'SAME'\nk3 = 3 # kernel_size = 3 x 3\nk5 = 5 # kernel_size = 5 x 5\np = 2 # pool_size = 2 x 2\nm = 0.15 # momentum\ndrop_rate = 0.3 # dropout\ndense1 = 1024\ndense2 = 512\n\n# %% [code]\n# Build and add layers\n\n# Define input layer\ninput_shape = (img_size, img_size, num_channels)\nfirst = Input(shape=input_shape)\n\ninput_layer = True\n\n# Add layers\nfor i in [32, 64, 128, 256]:\n    # i = number of filters\n    if input_layer: # input_shape required if first layer\n        model = Conv2D(filters=i, \n                         kernel_size=(k3,k3),\n                         padding=padding,\n                         activation=ReLU, \n                         input_shape=input_shape)(first)\n    else: \n        model = Conv2D(filters=i,\n                         kernel_size=(k3,k3),\n                         padding=padding,\n                         activation=ReLU)(model)\n    \n    # remaining layers \n    model = Conv2D(filters=i, \n                     kernel_size=(k3, k3), \n                     padding=padding, \n                     activation=ReLU)(model)\n    \n    model = Conv2D(filters=i, \n                     kernel_size=(k3, k3), \n                     padding=padding, \n                     activation=ReLU)(model)\n    \n    model = BatchNormalization(momentum=m)(model)\n    \n    model = MaxPool2D(pool_size=(p, p))(model)\n    \n    model = Conv2D(filters=i, \n                     kernel_size=(k5, k5), \n                     padding=padding, \n                     activation=ReLU)(model)\n    \n    if not input_layer:\n        model = BatchNormalization(momentum=m)(model)\n    \n    model = Dropout(rate=drop_rate)(model)\n    \n    input_layer = False\n\n## done\n\n# More layers\nmodel = Flatten()(model)\n\nmodel = Dense(dense1,\n              activation=ReLU)(model)\n\nmodel = Dropout(rate=drop_rate)(model)\n\ndense = Dense(dense2,\n              activation=ReLU)(model)\n\n# %% [code]\n# Define output layers \n\n# dense_o1 == dense_3 -> True\nroot_output = Dense(num_roots, \n                    activation=Softmax)(dense)\n\n# dense_o2 == dense_4 -> True\nv_diacritic_output = Dense(num_v_diacritics,\n                           activation=Softmax)(dense)\n\n# dense_o3 == dense_5 -> True\nc_diacritic_output = Dense(num_c_diacritics,\n                           activation=Softmax)(dense)\n\n# %% [code]\n# Declare model \n\nmodel = Model(inputs=first, \n              output=[root_output, \n                      v_diacritic_output, \n                      c_diacritic_output]) # muti-output\n\n# %% [code]\n# Compile model\n\nmodel.compile(loss=loss_func, optimizer=optimizer, metrics=metric)\n\n# %% [code]\n# Visual of model layers \n\nmodel.summary()\n\n# %% [markdown]\n# Since there is an incredible amount of computation to do, it is important that the learning rate is not too slow, and not so high that the loss function diverges. To achieve an optimal learning rate, a learning rate schedule will be used. This schedule will help to control the learning rate during training.\n\n# %% [code]\n# Create learning schedule\n\n# Function to use as input for LearningRateScheduler, returns a float\ndef step_decay(epochs):\n    \n    # set variables\n    initial_lrate = 1e-4\n    drop = 0.65\n    step_size = 10\n    \n    # calculate learning rate\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epochs)/step_size))\n    \n    return lrate\n\n## done\n\n# Get schedule\nLRSched = LearningRateScheduler(step_decay)\n\n# %% [markdown]\n# ## Data Augmentation\n\n# %% [markdown]\n# Data augmentation is the process of adding more data points to the dataset in an attempt to diversify the original dataset. This allows better training of the model since there are more inputs to learn from. \n# \n# Since the model produces multiple outputs, data augmentation must be done in a manner to preserve this quality.\n\n# %% [code]\n# Function to restructure y label for input to a data augmentation generator\n\ndef restructure_y_labels(dense_dict):\n    targets = None\n    lengths = {}\n    outputs = []\n    \n    for key, val in dense_dict.items():\n        if targets is None:\n            targets = val\n        else: \n            targets = np.concatenate((targets, val), axis=1)\n        \n        lengths[key] = val.shape[1]\n        outputs.append(key)\n    \n    return targets, lengths, outputs\n\n## done\n\n# %% [markdown]\n# The following code has been adapated from Kaushal Shah, who has also participated in the same challenge: https://tinyurl.com/tk9zhyg. Note that since the following class inputs a ImageDataGenerator, the same format as single-output generators can be used to perform data augmentation.\n\n# %% [code]\n# Code adapated from Kaushal Shah\n\n# Define custome Image Generator\nclass MultiOutputImageDataGenerator(ImageDataGenerator):\n\n    # Function to call customized flow method, with parent ImageDataGenerator\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32, #default\n             shuffle=True, #default\n             sample_weight=None,\n             subset=None):\n\n        # restructure the target labels first\n        targets, target_lengths, ordered_outputs = restructure_y_labels(y)\n\n        # generate batches of augmented data using flow from parent class (i.e. super())\n        for x_batch, y_batch in super().flow(x, targets, batch_size=batch_size, shuffle=shuffle):\n            target_dict = {}\n            ind = 0\n            for output in ordered_outputs:\n                l = target_lengths[output]\n                target_dict[output] = y_batch[:, ind:(ind+l)]\n                ind += l\n            \n            # yield batches \n            yield x_batch, target_dict\n\n## done\n\n# %% [code]\n# Perform data augmentation to generate more data\n\n# Create an instance of a MultiOutputDataGenerator\ndatagen = MultiOutputImageDataGenerator(\n    featurewise_center=False, \n    samplewise_center=False, \n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False, \n    zca_whitening=False,\n    rotation_range=10, \n    width_shift_range=0.20, \n    height_shift_range=0.20,\n    zoom_range=0.20,\n    horizontal_flip=False, \n    vertical_flip=False)\n\n## done\n\n# %% [markdown]\n# ## Training the CNN\n\n# %% [markdown]\n# After defining the basics of the CNN, then model must be fitted using the data. Note that the data is available through 4 parquet files. This implies that training must be done in 4 steps i.e. 4 loops.\n\n# %% [code]\n# Important variables\n\nepochs = 32\nbatch_size = 64\n\nw = 236\nh = 137\n\ns = 0.12 # test size\n\nmodel_history = {} # will collect history for plotting\n\n# %% [markdown]\n# #### Process Original Train:\n\n# %% [code]\n# Processing original train dataset \n\n# Drop grapheme column; not needed for training \nto_drop = ['grapheme']\ntrain = train.drop(to_drop, axis=1, inplace=False)\n\n# Change to unassigned integers 8 bits\ncnames = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\ntrain[cnames] = train[cnames].astype('uint8')\n\n# %% [markdown]\n# #### Resize Data:\n\n# %% [markdown]\n# The train dataset needs to be in a format which a CNN will be able to understand, and similarly the images must be resized from the original 137 x 236 size.\n\n# %% [code]\n# Function to resize images to indicated size for a specified dataframe\n\ndef resize_img(df, size=64, width=236, height=137):\n    resized_img_dict = {}\n    l = df.shape[0]\n    for i in range(l):\n        img = cv2.resize(df.loc[df.index[i]].values.reshape(height, width),\n                         (size,size),\n                         interpolation=cv2.INTER_AREA)\n        resized_img_dict[df.index[i]] = img.reshape(-1)\n    return pd.DataFrame(resized_img_dict).T\n\n## done\n\n# this function will be called during training \n\n# %% [markdown]\n# #### Load Training Data:\n\n# %% [code]\n# Function to load and format raw parquet data (for training)\n\ndef format_parquet_data(i, train):\n    start = timer()\n    # read in data\n    file_path = '/kaggle/input/bengaliai-cv19/train_image_data_' + str(i) + '.parquet'\n    parq_raw = pd.read_parquet(file_path)\n    \n    # need to combine with train using foreign key 'image_id'\n    train_ret = pd.merge(parq_raw, train, on='image_id')\n    \n    # drop 'image_id' column\n    to_drop = ['image_id'] # not needed for training\n    train_ret.drop(to_drop, axis=1, inplace=True)\n    \n    end = timer()\n    print('Time to load train_' + str(i) + ': ', int((end-start)//60), 'm', \n          int(round((end-start)%60, 0)), 's')\n    \n    return train_ret\n\n## done\n\n# %% [markdown]\n# #### Fit and Train Model:\n\n# %% [markdown]\n# As mentioned above, this will be done in 4 iterations for each of the 4 training sets.\n\n# %% [code]\n# Training the model\n\n# Loop for training \nstart = timer()\nfor i in range(4):\n    \n    start_train = timer()\n    start_proc = timer()\n    \n    # get train \n    train_curr = format_parquet_data(i, train)\n    \n    # resize images \n    to_drop = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n    X = train_curr.drop(to_drop, axis=1, inplace=False)\n    X = resize_img(X)\n   \n    # normalize images\n    X = X/255\n    \n    # one-hot encode columns, returns target labels\n    Y_roots = to_categorical(train_curr.grapheme_root)\n    Y_v_diacritics = to_categorical(train_curr.vowel_diacritic)\n    Y_c_diacritics = to_categorical(train_curr.consonant_diacritic)\n    \n    del train_curr\n    \n    # Keras is batch first, use -1 for dynamic\n    X = X.values.reshape(-1, img_size, img_size, num_channels)\n    \n    # split into train and test\n    train_X, test_X, train_y_r, test_y_r, train_y_v, test_y_v, train_y_c, test_y_c = train_test_split(X, \n                                                                                                     Y_roots, \n                                                                                                     Y_v_diacritics, \n                                                                                                     Y_c_diacritics, \n                                                                                                     test_size=s, \n                                                                                                     random_state=42)\n     \n    del X\n    del Y_roots, Y_v_diacritics, Y_c_diacritics\n    \n    end_proc = timer()\n    print('Time to process train_' + str(i) + ': ', int((end_proc-start_proc)//60), 'm', \n          int(round((end_proc-start_proc)%60, 0)), 's')\n    \n    # fit the model\n    start_fit = timer()\n    datagen.fit(train_X)\n    \n    # target labels \n    labels = {'dense_3': train_y_r, 'dense_4': train_y_v, 'dense_5': train_y_c}\n    \n    history_curr = model.fit_generator(datagen.flow(x=train_X, y=labels, batch_size=batch_size),\n                                       epochs=epochs, \n                                       validation_data=(test_X,[test_y_r, test_y_v, test_y_c]), \n                                       steps_per_epoch=train_X.shape[0]//batch_size, \n                                       callbacks=[LRSched])\n    \n    end_train = timer()\n    \n    print('Time to train model for train_' + str(i) + ': ', int((end_train-start_train)//60), 'm', \n          int(round((end_train-start_train)%60, 0)), 's')\n    \n    # add to history dictionary for model analysis\n    model_history[i] = history_curr\n    \n    del train_X, test_X\n    del train_y_r, test_y_r, train_y_v, test_y_v, train_y_c, test_y_c \n    \n    gc.collect()\n    \n## done\n\nend = timer()\nprint('Time to train model overall: ', int((end-start)//60), 'm', \n      int(round((end-start)%60, 0)), 's')\n\n# %% [markdown]\n# #### Model Analysis:\n\n# %% [code]\n# Function to plot model accuracy as each epoch is calculated\n\ndef plot_model_accuracy(model_history, epochs, i):\n    \n    # setup plots\n    sns.set_style('darkgrid')\n    fig, ax = pt.figure()\n    xvalues = range(epochs).tolist()\n    labels = ['Train Root Accuracy', 'Train Vowel Accuracy', 'Train Consonant Accuracy',\n             'Test Root Accuracy', 'Test Vowel Accuracy', 'Test Consonant Accuracy']\n    \n    # add lines\n    sns.lineplot(x=xvalues, y=model_history['dense_3_accuracy'], ax=ax)\n    sns.lineplot(x=xvalues, y=model_history['dense_4_accuracy'], ax=ax)\n    sns.lineplot(x=xvalues, y=model_history['dense_5_accuracy'], ax=ax)\n    sns.lineplot(x=xvalues, y=model_history['val_dense_3_accuracy'], ax=ax)\n    sns.lineplot(x=xvalues, y=model_history['val_dense_4_accuracy'], ax=ax)\n    sns.lineplot(x=xvalues, y=model_history['val_dense_5_accuracy'], ax=ax)\n    \n    # add labels\n    pt.title('Accuracy for Train_' + str(i))\n    pt.xlabel('Epoch')\n    pt.ylabel('Accuracy')\n    fig.legend(labels=labels)\n    \n    pt.show()\n    \n## done\n\n# %% [code]\n# Plot accuracy\n\nfor i in range(4):\n    plot_model_accuracy(model_history[0], epochs, i)\n\n# %% [markdown]\n# ## Submission\n\n# %% [markdown]\n# Making predictions and formatting in Kaggle-suggested method. \n\n# %% [code]\n# Important variables: \n\ngrapheme_comp = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic'] # in order of submission\n\nrow_id = [] # name of row in submission.csv\ntarget = [] # prediction in submission.csv\n\n# %% [code]\n# Function to load and format raw parquet data (for testing)\n\ndef format_parquet_data_test(i):\n    # read in data\n    file_path = '/kaggle/input/bengaliai-cv19/test_image_data_' + str(i) + '.parquet'\n    parq_raw = pd.read_parquet(file_path)\n    \n    # set index\n    parq_raw.set_index('image_id', inplace=True)\n    \n    # process datadrame\n    test = resize(parq_raw)\n    test = test/255\n    test = test.values.reshape(-1, img_size, img_size, num_channels)\n\n    return test\n\n## done\n\n# Define test datasets \ntest_0 = format_parquet_data_test(0)\ntest_1 = format_parquet_data_test(1)\ntest_2 = format_parquet_data_test(2)\ntest_3 = format_parquet_data_test(3)\n\n# %% [code]\n# Create dictionary for storing intermediary predictions\n\npred_storage = {'grapheme_root': [],\n                'vowel_diacritic': [],\n                'consonant_diacritic': []}\n\n# %% [code]\n# Loop for testing and formatting for submission.csv\n\nfor i, test in enumerate([test_0, test_1, test_2, test_3]):\n    \n    # make predictions\n    predictions = model.predict(test) # will return 3 numpy arrays \n\n    # add predictions to lists\n    for j, image_id in enumerate(test.index.values):\n        for k in range(3):\n            \n            # get name and and prediction value\n            name = 'Test_' + str(image_id) + '_' + grapheme_comp[k]\n            loc = predictions[k][j]\n            \n            # append name and prediction value\n            row_id.append(name)\n            target.append(np.argmax(loc))\n\n# %% [code]\n# Create dataframe and submission.csv\n\n# Format into dataframe\nsubmission = pd.DataFrame(data={'row_id': row_id,\n                                'target':target},\n                          columns = ['row_id','target'])\n\n# Ensure correct formatting\nsubmission.head(10)\n\n# Write to submission.csv\nsubmission.to_csv('submission.csv',index=False)\n\n# %% [markdown]\n# Submit predictions!\n\n# %% [code]\nclass_map = pd.read_csv(\"../input/bengaliai-cv19/class_map.csv\")\nsample_submission = pd.read_csv(\"../input/bengaliai-cv19/sample_submission.csv\")\ntest = pd.read_csv(\"../input/bengaliai-cv19/test.csv\")\ntrain = pd.read_csv(\"../input/bengaliai-cv19/train.csv\")","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}